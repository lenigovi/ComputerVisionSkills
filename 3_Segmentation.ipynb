{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "\n",
    "The goal of segmentation is identify the boundaries between different objects in an image, and to simplify the representation of an image into meaningful boundaries that are easier to analyze. This topic is important because:\n",
    "- it is a more basic step for the convolutional filters in Neural Networks for extracting image features\n",
    "- it is the basis for many other image processing tasks such as object detection, object tracking, and image classification\n",
    "\n",
    "\\\n",
    "Image segmentation can be classified into three categories:\n",
    "Semantic segmentation\n",
    "Instance segmentation\n",
    "Panoptic segmentation\n",
    "\n",
    "The document will cover the following topics:\n",
    "- Segmentation as pixel wise classification\n",
    "    - Probabilistic classification\n",
    "    - Mixture of Gaussians, EM\n",
    "\n",
    "- Segmentation as energy minimization\n",
    "    - Markov Random Fields\n",
    "    - Energy formulation\n",
    "\n",
    "- Graph cuts for image segmentaton\n",
    "    - Basic idea\n",
    "    - s-t Mincut Algorithm\n",
    "    - Extension to non-binary case\n",
    "\n",
    "\n",
    "\n",
    "\\\n",
    "Definition of The Problem\\\n",
    "Identifying groups of pixels in the input which is the image. This is a semantic segmentation, this means all the pixels that belong to a title are grouped together. For example, semantically meaningful groups such as color similarity,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Segmentation Approaches:\n",
    "- Unsupervised Clustering\n",
    "    - Grouping what \"looks similar\"\n",
    "- Semantic Segmentation\n",
    "    - Learn a classifier to assign a semantic class $C_k$ to every pixel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation as Pixel-Wise Classification\n",
    "\n",
    "To define the grouping semantics, we use feature space. Grayscale image pixels are classified based on intensity similarity as a 1D representation, while colored images are classified based on color value similarity as a 3D representation.\n",
    "\n",
    "A filter Bank of 24 filters allow us to operate in 24-dimension. \n",
    "\n",
    "\n",
    "\\\n",
    "Basically the method is to apply a threshold, above which is the foreground, and below is the background.\n",
    "\n",
    "\n",
    "### Probabilistic Classification\n",
    "- Bayesian Classification\n",
    "    - Given a measurement $x$, what semantic class $C_k$ should we assign to a pixel?\n",
    "    - We must recall Bayes Decision Theory in this section (posterior probability):\n",
    "        - $P(C_k|x) = \\frac{p(x|C_k)p(C_k)}{\\sum_{j}p(x|C_j)p(C_j)} $\n",
    "        - where: \n",
    "            - $p(x|C_k)$ is the likelihood of the measurement $x$ having been generated by class $C_k$\n",
    "            -  $p(C_k)$ is the prior probability of class $C_k$\n",
    "    - In order to build a classifier, we can try either:\n",
    "        - Discriminative Methods: directly estimating the posterior\n",
    "        - Generative Methods: estimating likelihood and prior, and then using the Bayes Decision formula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In image recognition, a machine learning model can be taught to recognize objects. Next section will explore how machines recognize classifications by finding patterns. In order to explore the segmentation subject further, we need to take a look at Machine Learning Data Models first to understand the context better.\n",
    "\n",
    "\n",
    "### Machine Learning Data Models\n",
    "\n",
    "A machine Learning data model is a program that expresses the relationship between data and finds patterns in the dataset. When an unseen dataset is expressed in a ML data model, the model creates meaningful connections between data, and this can help us make decisions. For example, in natural language processing, machine learning models can parse and correctly recognize the context behind previously unheard sentences or combinations of words.\n",
    "\n",
    "Machine learning data models can be classified into two types: Generative and Discriminative Models\n",
    "\n",
    "- A generative model focuses on learning the underlying probability distribution of a given dataset. The fundamental idea behind generative models is to create a model that can generate new data points statistically similar to the original dataset, and new data points are generated from the probability distribution. This model type learns the patterns between data, and creates new realistic networks stemming from one value. This is why, the model focuses on learning the probability distribution that generates data, rather than the classification of data.\n",
    "Examples:\n",
    "    - Image or Face generation with Generative adversarial networks (GANs) \n",
    "    - Text generation\n",
    "    - Anomaly detection\n",
    "    - Gaussian mixture model learning the parameters of the Gaussian mixture that best fits the data \\\n",
    "&nbsp;\n",
    "\n",
    "- A discriminative model focuses on learning which x-value will map to which y-value. In other words, it learns the direct mapping between input variables and output labels (aka the classification of data) through learned boundaries without considering the underlying probability distribution of the data. The discriminative model learns to find the decision boundary that separates different classes or categories in the input space. This model type can make predictions on previously unseen data based on conditional probability and can be used either for classification or regression problem statements. \n",
    "For example: \n",
    "    - A convolutional neural network recognizing what an object in an image is\n",
    "    - A program that predicts the price of a house based on its features\n",
    "    - Logistic regression program performing sentiment analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"left\">\n",
    "  <img src=\"Segmentation\\img\\generativedatamodel.jpg\" width=45% />\n",
    "  <img src=\"Segmentation\\img\\discriminativedatamodel.jpg\" width=45% /> \n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;\">\n",
    "        <div style =\"padding-left\" 10>\n",
    "            <h3>Generative Model</h3>\n",
    "            <p>A generative model focuses on learning the underlying probability distribution of a given dataset. The fundamental idea behind generative models is to create a model that can generate new data points statistically similar to the original dataset, and new data points are generated from the probability distribution. This model type learns the patterns between data, and creates new realistic networks stemming from one value. This is why, the model focuses on learning the probability distribution that generates data, rather than the classification of data.\n",
    "            \n",
    "Examples:\n",
    "<ul>\n",
    "<li>Image or Face generation with Generative adversarial networks (GANs)</li>\n",
    "<li>Text generation</li>\n",
    "<li>Anomaly detection</li>\n",
    "<li>Gaussian mixture model learning the parameters of the Gaussian mixture that best fits the data</li>\n",
    "</ul>\n",
    "</p>\n",
    "        </div>\n",
    "        <div style =\"padding-right\" 10>\n",
    "            <h3>Discriminative Model</h3>\n",
    "            <p>A discriminative model focuses on learning which x-value will map to which y-value. In other words, it learns the direct mapping between input variables and output labels (aka the classification of data) through learned boundaries without considering the underlying probability distribution of the data. The discriminative model learns to find the decision boundary that separates different classes or categories in the input space. This model type can make predictions on previously unseen data based on conditional probability and can be used either for classification or regression problem statements.\n",
    "            \n",
    "Examples:\n",
    "<ul>\n",
    "<li>A convolutional neural network recognizing what an object in an image is</li>\n",
    "<li>A program that predicts the price of a house based on its features</li>\n",
    "<li>Logistic regression program performing sentiment analysis</li>\n",
    "<ul>\n",
    "</p>\n",
    "        </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Mixture Model of Gaussian Distribution (MoG)\n",
    "A mixture model is a statistical model used for representing data that may arise from a mixture of different probability distributions. In simpler terms, it's a way to describe data that might come from several different sources or populations.\n",
    "\n",
    "For estimating the parameters of a mixture model, we determine component distributions and their corresponding weights, with methods like expectation-maximization (EM) algorithm or Bayesian inference.\n",
    "\n",
    "Mixture Model of Gaussian Distribution (MoG) is a specific type of mixture model where the data distributions are Gaussian (also known as normal) distributions. MoG offers a flexible data distribution. In a Gaussian mixture model, the assumption is that the observed data is generated by a mixture of several Gaussian distributions with different means and variances. Therefore it is a generative data model.\n",
    "\n",
    "Mixture Model of Gaussian Distribution will be referred as MoG here on. MoG can be expressed so:\n",
    "$$ p(x) = \\sum_{i=1}^{K} \\phi_i \\mathcal{N}(x|\\mu_i, \\Sigma_i) $$\n",
    "\n",
    "where,\n",
    "- $p(x)$ is the probability density function of the mixture model\n",
    "- $\\phi_i$ is the mixing coefficient for the $i$-th component\n",
    "- $\\mathcal{N}(x|\\mu_i, \\Sigma_i)$ represents the Gaussian distribution with mean $\\mu_i$ and covariance matrix $\\Sigma_i$\n",
    "- $K$ is the number of components in the mixture\n",
    "\n",
    "&nbsp;\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation-Maximization (EM) Algorithm\n",
    "The Expectation-maximization algorithm (EM), is an iterative method for performing maximum likelihood in certain models.\n",
    "\n",
    " - E-Step: assigns samples to mixture model components:\n",
    "    - $ \\pi_j \\gamma_j(x_n) $\n",
    "\n",
    "\n",
    "User Assisted Image Segmentation\n",
    "- User marks two regions for foreground and background\n",
    "- Learn a MoG model for the color values in each region\n",
    "- Use the models to classify all pixels by deciding for the class with the highest posterior probability\n",
    "\n",
    "M-Step: re-estimates the parameters (separately for each mixture component) based on the soft assignment\n",
    "$$ \\^{N}_j \\leftarrow \\sum_{n=1}^{N}\\gamma_j(x_n) $$\n",
    "\n",
    "### Pros of MoG, EM\n",
    "- It provides an interpretation of the task probability functions\n",
    "- It is a generative model as the values can be generated from the distribution, and it can predict novel data points\n",
    "\n",
    "#### Cons of MoG, EM\n",
    "- Local minima\n",
    "    - k-means is NP-hard (see: computational complexity theory, nondeterministic polynomial time) even with k=2\n",
    "- Initialization\n",
    "    - Often a good idea to start with some k-means iteration\n",
    "- Needs to know number of componens\n",
    "    - Solution: Model selection\n",
    "- Needs careful implementation to avoid numerical issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats\n",
    "\n",
    "So far we have explored  bottom-up ways for segmentation, for which we examined individual pixels and neighborhoods to segment an image into regions. Due to the problem for recognition in finding meaningful segments, alternative methods are explored. When the methods in pixel-wise segmentation are applied to real world datasets, they result in very noisy segmentations.\n",
    "\n",
    "We would like to enforce region constraints with spatial consistency and smooth borders.\n",
    "\n",
    "For this, in the next section, we will explore pixel neighborhood relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References for this Section\n",
    "\n",
    "---\n",
    "\n",
    "[1] v7labs, https://www.v7labs.com/blog/panoptic-segmentation-guide\n",
    "\n",
    "[2] fiveMinuteStats, EM, https://stephens999.github.io/fiveMinuteStats/intro_to_em.html\n",
    "\n",
    "[3] fiveMinuteStates, Mixture Models, https://stephens999.github.io/fiveMinuteStats/intro_to_mixture_models.html\n",
    "\n",
    "[4] neptune.ai, https://neptune.ai/blog/image-segmentation\n",
    "\n",
    "[5] Mordatch, Igor, \"Concept Learning with Energy-Based Models\" OpenAI. https://openreview.net/pdf?id=H12Y1dJDG\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation as Energy Minimization\n",
    "\n",
    "In the previous section, we explored semantic pixel based clustering approaches for segmentation. In this section, we will explore Energy Minimization methods.\n",
    "\n",
    "### Markov Random Fields\n",
    "\n",
    "Markov Random Fields (MRF) is a method to model a joint distribution of an undirected, connected graph where each node implies a random variable and each edge between nodes is a modeled stochastic dependency.\n",
    "\n",
    "MRF is an undirected graphical model that explicitly expresses the conditional independence relationship between nodes.\n",
    "\n",
    "In MRF, we use a class of graphical models to model the conditional probability of a random variable with its given parents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Segmentation/img/mrf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Random Fields\n",
    "\n",
    "We would like to minimize an energy by using neighboring relations, therefore we use a classifier that predicts a label for a single sample without considering \"neighbouring\" samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Energy Formulation\n",
    "\n",
    "Joint Probability\\\n",
    "$p(x,y) = \\prod_{i} \\phi(x_i,y_i) \\prod_{i}\\psi(x_i,x_j)$\n",
    "\n",
    "Energy Function\\\n",
    "$E(x,y) = \\sum_{i}\\underbrace{\\phi(x_i,y_i)}_\\text{SNP} + \\sum_{i,j}\\underbrace{\\phi(x_i,x_j)}_\\text{PWP} $ \n",
    "\n",
    "Single-node Potential (Unary Potentials)\n",
    "- Encode local information about the given pixel/patch\n",
    "\n",
    "\\\n",
    "Pair-wise Potential (Binary Potentials)\n",
    "- Encode neighborhood infromation\n",
    "\n",
    "\n",
    "![](Segmentation/img/mrfstructure.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$ -logp(x,y) = - \\sum_{i} \\log \\psi(x_i,y_i)$\n",
    "\n",
    "Local Optima of Energy Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Cut Method\n",
    "\n",
    "One of the most effective methods in segmentation is the Graph Cut method. The main idea is to represent the image as a graph and find the cut between segments. In this section we explore converting EM problem to Graph problem. Main idea is to convert MRF into a source-sink graph. \n",
    "\n",
    "In order to understand better, first we need to make the terminology clear.\n",
    "\n",
    "`Flow Network`: In graph theory, a flow network is a directed graph where each edge has a capacity and receives a flow. The vertices are called nodes, and edges are called arcs.\n",
    "\n",
    "`Graph`: In Graph Theory, a Graph is a non-linear data structure consisting of vertices and edges. The vertices are sometimes also referred to as nodes and the edges are lines or arcs that connect any two nodes in the graph. More formally a Graph is composed of a set of vertices( V ) and a set of edges( E ). The graph is denoted by G(V, E).\n",
    "\n",
    "`Cut`: A cut is a partition of the vertices of a graph into two disjoint subsets, such that the source node is in one set and the sink node is in the other. In a flow network, an `s–t` cut is a cut that requires the source and the sink to be in different subsets, and its cut-set only consists of edges going from the source's side to the sink's side. The capacity of an s–t cut is defined as the sum of the capacity of each edge in the cut-set.\n",
    "\n",
    "### s-t MaxFlow MinCut Theorem\n",
    "\n",
    "In optimization theory, the MaxFlow MinCut Theorem states that, in a flow network, the max amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut. This means that, if minimum cut, which is the smallest total weight of the edges, is removed, it would disconnect the source from the sink. In other words, the weight of a cut is the sum of the capacities of the edges that cross from one set to the other. A min-cut is a cut with the smallest total weight. In any flow network, the maximum amount of flow that can be pushed from the source to the sink is equal to the total weight of the edges in a minimum cut. The maximum flow that can be achieved is constrained by the smallest total capacity of the edges that, if removed, would disconnect the source from the sink. \n",
    "\n",
    "This theorem, at its core, states that the max flow one can achieve is directly related to the min bottleneck in the network that stops the flow.\n",
    "\n",
    "\n",
    "Foreground: Source \\\n",
    "Background: Sink\n",
    "\n",
    "\n",
    "Weights of a node $i$ $(x_i, y_i)$ with the node $j$ $(x_j, y_j)$ can be found by:\n",
    "\n",
    "$$ \\frac{e^{\\frac{-||f(x_i, y_i)-f(x_j, y_j)||}{2\\sigma^2}}}{\\sqrt{(x_i-x_j)^2+(y_i-y_j)^2}}    $$ \n",
    "\n",
    "\n",
    "Here we will refer to the Matlab practice below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "\n",
    "Graph *g;\n",
    "\n",
    "For all pixels p \n",
    "     nodeID(p) = g->add_node();\n",
    "     set_weights(nodeID(p),fgCost(p),bg(Cost(p)));\n",
    "end\n",
    "\n",
    "for all adjacent pixels p,q\n",
    "    add_weights(nodeID(p),nodeID(q),cost(p,q);)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "img = cv2.imread('Image Processing\\img\\gaussian_original.jpg')\n",
    "\n",
    "# Initialize a graph\n",
    "g = nx.Graph()\n",
    "\n",
    "\n",
    "def color_cost(p, q):\n",
    "    color_diff = np.sqrt(np.sum((p - q)**2))\n",
    "    return abs(sum(p) - sum(q))\n",
    "\n",
    "# Functions to calculate foreground and background costs for a pixel\n",
    "def fg_cost(p):\n",
    "\n",
    "    return 0\n",
    "\n",
    "def bg_cost(p):\n",
    "\n",
    "    return 0\n",
    "\n",
    "# Add nodes for all pixels and set weights\n",
    "for pixel in img:\n",
    "    node_id = g.add_node(pixel)\n",
    "    fg_cost_val = fg_cost(pixel)\n",
    "    bg_cost_val = bg_cost(pixel)\n",
    "    g.nodes[node_id]['fg_cost'] = fg_cost_val\n",
    "    g.nodes[node_id]['bg_cost'] = bg_cost_val\n",
    "\n",
    "# Add edges between adjacent pixels and set weights\n",
    "for p, q in nx.edges(g):\n",
    "    cost_val = color_cost(p, q) \n",
    "    g.edges[p, q]['cost'] = cost_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element B : True\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "def bfs(graph, start, search_value):\n",
    "    visited = set()\n",
    "    queue = deque([start])\n",
    "\n",
    "    while queue:\n",
    "        vertex = queue.popleft()\n",
    "        if vertex == search_value:\n",
    "            return True\n",
    "        visited.add(vertex)\n",
    "    \n",
    "        for neighbour in graph[vertex]:\n",
    "            if neighbour not in visited:\n",
    "                queue.append(neighbour)\n",
    "                visited.add(neighbour)\n",
    "    return False\n",
    "\n",
    "graph = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['A', 'D', 'E'],\n",
    "    'C': ['A', 'F'],\n",
    "    'D': ['B'],\n",
    "    'E': ['B', 'F'],\n",
    "    'F': ['C', 'E']\n",
    "}\n",
    "\n",
    "start = \"F\"\n",
    "search_value = \"B\"\n",
    "res = bfs(graph, start, search_value)\n",
    "print(f\"element {search_value} : {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Cut Bias and Normalized Cut\n",
    "\n",
    "The min cut algorithm tends to produce small isolated segments which causes a bad partition. In order to adjust the weight of cut proportionally to the number of edges in the cut, we use the normalized cut solution which normalizes size of the segments and fixes the min cut bias.\n",
    "\n",
    "$$ N_{cut}(A,B)=\\frac{cut(A,B)}{assoc(A,V)} + \\frac{cut(A,B)}{assoc(B,V)} $$\n",
    "\n",
    "where\n",
    "- $assoc(A,V)$ is the sum of weights of all edges that touch node $A$. \n",
    "\n",
    "Generalized eigenvalue problem is the approximate solution for minimizing the N-cut value. Let $W$ be the adjacency matrix of the graph. Let $D$ be the diagonal matrix with diagonal entries.\n",
    "\n",
    "$$ D(i,j) = \\sum_{i}w(i,j) $$\n",
    "\n",
    "Then normalized cut cost can be written as\n",
    "\n",
    "$$ \\frac{y^T(D-w)y}{y^TDy} $$\n",
    "\n",
    "where\n",
    "- y is an indicator vector with the 1 in the $i^{th}$ position if the $i^{th}$ feature point belongs to A, negative constant otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### References for this Section\n",
    "\n",
    "[1] Jun-DevpBlog https://medium.com/jun94-devpblog/cv-7-segmentation-as-energy-minimization-markov-random-fields-energy-formulation-graph-cut-670b9b3c82ee\n",
    "\n",
    "[2] Statistical Techniques in Robotics, CMU https://www.cs.cmu.edu/~16831-f14/notes/F11/16831_lecture07_bneuman.pdf\n",
    "\n",
    "[3] https://jwmi.github.io/ASM/Murphy%20chapter%2019.pdf\n",
    "\n",
    "[4] https://en.wikipedia.org/wiki/Cut_(graph_theory)\n",
    "\n",
    "[5] https://pub.ista.ac.at/~vnk/software.html\n",
    "\n",
    "[6] https://julie-jiang.github.io/image-segmentation/\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Binary Energy Problems\n",
    "\n",
    "When dealing with non-binary energies, we are faced with the issue that multi-label problems are NP-hard when there are 3 or more labels. Approximation algorithms extend graph cuts to the multi label case and offer a solution:\n",
    "- $\\alpha$-Expansion\n",
    "- $\\alpha\\beta$-Swap\n",
    "\n",
    "They are no longer guaranteed to return the globally optimal result, however $\\alpha$-Expansion has a guaranteed approximation quality (2-approx) and converges in a few iterations.\n",
    "\n",
    "The key idea is to have multiclass segmentation problem, which means one node for every class, we pick one of the nodes -which is called \"$\\alpha$\"- and assign it as the source, and then we pick one of the nodes from other labels (classes) and assign it sink.\n",
    "\n",
    "Example: Stereo Vision and Depth Map\n",
    "Depth maps contain information about the distance of objects from a specific perspective or reference point. Each pixel is assigned a value to represent the distance of that pixel from the reference point which creates a 3D representation of the scene for its RGB image or virtual scene. In each $\\alpha$-expansion a given label $\\alpha$ grabs space from other labels.\n",
    "\n",
    "![](Segmentation/img/depthmapping.png)\n",
    "\n",
    "![](Segmentation/img/depthmapgif.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References for this Section\n",
    "\n",
    "[1] Looking Glass Factory https://lookingglassfactory.com/blog/depth-map\n",
    "\n",
    "[2]\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
